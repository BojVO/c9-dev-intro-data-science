{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Course Code for Azure Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup this notebook with the existing experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "from azureml.core import Workspace, Experiment, Dataset\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.train.automl.run import AutoMLRun\n",
    "from datetime import datetime\n",
    "\n",
    "# Recreate our Local variables\n",
    "target_column_name = 'cnt'\n",
    "time_column_name = 'date'\n",
    "max_horizon = 14\n",
    "\n",
    "# Connect to the workspace and experiment again\n",
    "ws = Workspace('INSERT_YOUR_SUBSCRIPTION_ID', 'INSERT_YOUR_RESOURCE_GROUP_NAME', 'INSERT_YOUR_RESOURCE_NAME')\n",
    "experiment_name = 'INSERT_YOUR_EXPERIMENT_NAME'\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "\n",
    "# Connect to the compute cluster again\n",
    "amlcompute_cluster_name = \"INSERT_YOUR_CLUSTER_NAME\"\n",
    "cts = ws.compute_targets\n",
    "compute_target = cts[amlcompute_cluster_name]\n",
    "\n",
    "# Connect to the dataset from within the datastore again\n",
    "datastore = ws.get_default_datastore()\n",
    "dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, 'dataset/bike-no.csv')]).with_timestamp_columns(fine_grain_timestamp=time_column_name) \n",
    "dataset.to_pandas_dataframe().reset_index(drop=True)\n",
    "\n",
    "# Connect to the most recent run again\n",
    "run_id = 'INSERT_YOUR_RUN_ID'\n",
    "remote_run = AutoMLRun(experiment, run_id)\n",
    "remote_run\n",
    "\n",
    "# Recreate the test data\n",
    "test = dataset.time_after(datetime(2012, 9, 1), include_boundary=True)\n",
    "test.to_pandas_dataframe().head(5).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the information from the run and model with the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_run.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run, fitted_model = remote_run.get_output()\n",
    "fitted_model.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the features from the fitted run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model.named_steps['timeseriestransformer'].get_engineered_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurization_summary = fitted_model.named_steps['timeseriestransformer'].get_featurization_summary()\n",
    "pd.DataFrame.from_records(featurization_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing, make sure you have uploaded the files from the forecast folder with:\n",
    "- `forecasting_helper.py`\n",
    "- `forecasting_script.py`\n",
    "- `metrics_helper.py`\n",
    "- `run_forecast.py`\n",
    "\n",
    "You can find these on the [course repo in the project folder](https://github.com/microsoft/c9-dev-intro-data-science/tree/main/regression-with-bikes/forecast/) and it should be uploaded to your Azure Machine Learning Studio notebook folder where this notebook is running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model with a rolling forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_forecast import run_rolling_forecast\n",
    "\n",
    "test_experiment = Experiment(ws, experiment_name + '_test')\n",
    "remote_run = run_rolling_forecast(test_experiment, compute_target, \n",
    "                                  best_run, test, max_horizon, \n",
    "                                  target_column_name, time_column_name)\n",
    "remote_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_run.wait_for_completion(show_output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the output of the test run predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_run.download_file('outputs/predictions.csv', 'predictions.csv')\n",
    "df_all = pd.read_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.automl.core._vendor.automl.client.core.common import metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from matplotlib import pyplot as plt\n",
    "from automl.client.core.common import constants\n",
    "\n",
    "print(\"Simple forecasting model\")\n",
    "rmse = np.sqrt(mean_squared_error(df_all[target_column_name], df_all['predicted']))\n",
    "print(\"[Test Data] \\nRoot Mean Squared Error: %.2f\" % rmse)\n",
    "\n",
    "mae = mean_absolute_error(df_all[target_column_name], df_all['predicted'])\n",
    "print('mean_absolute_error score: %.2f' % mae)\n",
    "\n",
    "mape = MAPE(df_all[target_column_name], df_all['predicted'])\n",
    "print('MAPE: %.2f' % mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the accuracy with mean absolute percentage error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot outputs\n",
    "%matplotlib inline\n",
    "test_pred = plt.scatter(df_all[target_column_name], df_all['predicted'], color='b')\n",
    "test_test = plt.scatter(df_all[target_column_name], df_all[target_column_name], color='g')\n",
    "plt.legend((test_pred, test_test), ('prediction', 'truth'), loc='upper left', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the statistical method for a more accurate representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics_helper import MAPE, APE\n",
    "df_all.groupby('horizon_origin').apply(\n",
    "    lambda df: pd.Series({'MAPE': MAPE(df[target_column_name], df['predicted']),\n",
    "                          'RMSE': np.sqrt(mean_squared_error(df[target_column_name], df['predicted'])),\n",
    "                          'MAE': mean_absolute_error(df[target_column_name], df['predicted'])}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the accurate scoring of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_APE = df_all.assign(APE=APE(df_all[target_column_name], df_all['predicted']))\n",
    "APEs = [df_all_APE[df_all['horizon_origin'] == h].APE.values for h in range(1, max_horizon + 1)]\n",
    "\n",
    "%matplotlib inline\n",
    "plt.boxplot(APEs)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('horizon')\n",
    "plt.ylabel('APE (%)')\n",
    "plt.title('Absolute Percentage Errors by Forecast Horizon')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the best model as a web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = 'AutoML_ae9ab50d-2f83-47a6-8749-db262953c8cb'\n",
    "training_run = AutoMLRun(experiment, run_id)\n",
    "training_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = best_run.properties['model_name']\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_file_name = 'inference/score.py'\n",
    "best_run.download_file('outputs/scoring_file_v_1_0_0.py', 'inference/score.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"Bike Share AutoML Model\"\n",
    "model = training_run.register_model(model_name = model_name,\n",
    "                                    description = description,\n",
    "                                    tags = None)\n",
    "print(training_run.model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "inference_config = InferenceConfig(entry_script=script_file_name, environment=best_run.get_environment())\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1,\n",
    "                                               memory_gb = 1,\n",
    "                                               tags = {'type': \"automl-forecasting\"},\n",
    "                                               description = 'Sample service for AutoML Forecasting')\n",
    "\n",
    "aci_service_name = 'automl-bike-sharing'\n",
    "print(aci_service_name)\n",
    "aci_service = Model.deploy(ws, aci_service_name, [model], inference_config, aciconfig)\n",
    "aci_service.wait_for_deployment(True)\n",
    "print(aci_service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requries that the bike-no-horizon.csv is uploaded to the Azure Machine Learning notebook folder\n",
    "test_df = pd.read_csv('./bike-no-horizon.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "test_sample = json.dumps({'data': test_df.to_dict(orient='records')})\n",
    "response = aci_service.run(input_data = test_sample)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = json.loads(response)\n",
    "y_fcst_all = pd.DataFrame(res_dict['index'])\n",
    "y_fcst_all[time_column_name] = pd.to_datetime(y_fcst_all[time_column_name], unit = 'ms')\n",
    "y_fcst_all['forecast'] = res_dict['forecast']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the predictions using the web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webservice_df = pd.DataFrame({ 'Truth': test_df['cnt'], 'Forecast': y_fcst_all['forecast'] } )\n",
    "webservice_df['APE'] = APE(webservice_df['Truth'], webservice_df['Forecast'])\n",
    "webservice_df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}